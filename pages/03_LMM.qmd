---
title: "Linear Mixed Models"
date: "last-modified"
echo: true 
warning: false 
message: false
---
  
```{r}
#| echo: False
library(tidyverse)
library(emmeans)
library(lme4)
library(MASS)
library(LMMsolver)
library(agriutilities)
library(ggpubr)
library(gridExtra)
```

## 1) Solving Mixed Models Equations

> A mixed model, mixed-effects model or mixed error-component model is a statistical model containing both fixed effects and random effects

First, let's load our data

```{r}
getwd()
data <- read.csv("../data/example_1.csv") |>
  mutate(gen = as.factor(gen), block = as.factor(block))
head(data)
n <- 12
n_blks <- 3
n_gens <- 4
```

THe most common way to obtain BLUEs and BLUPs is to solve the Henderson Equation.
To do so, first,  we need to estimate the variances of the random components. 
Later on, we will show how to do so using Restricted Maximum Likelihood (REML), 
but for now we will use the methods of moments. So, let's assume the following model

$$y = \mu + b + g + \epsilon, \text{where } g \sim N(0, I\sigma^2_g) \text{ and } \epsilon \sim N(0, I\sigma^2_e)$$
  
  which can be also expressed as:
  
$$y = X\beta + Zu + \epsilon = \begin{bmatrix}
1 \ 0 \ 0 \\
0 \ 1 \ 0 \\
0 \ 0 \ 1 \\
1 \ 0 \ 0 \\
0 \ 1 \ 0 \\
0 \ 0 \ 1 \\
1 \ 0 \ 0 \\
0 \ 1 \ 0 \\
0 \ 0 \ 1 \\
1 \ 0 \ 0 \\
0 \ 1 \ 0 \\
0 \ 0 \ 1 \\
\end{bmatrix} \beta + 
  \begin{bmatrix}
1 \ 0 \ 0 \ 0 \\
1 \ 0 \ 0 \ 0 \\
1 \ 0 \ 0 \ 0 \\
0 \ 1 \ 0 \ 0 \\
0 \ 1 \ 0 \ 0 \\
0 \ 1 \ 0 \ 0 \\
0 \ 0 \ 1 \ 0 \\
0 \ 0 \ 1 \ 0 \\
0 \ 0 \ 1 \ 0 \\
0 \ 0 \ 0 \ 1 \\
0 \ 0 \ 0 \ 1 \\
0 \ 0 \ 0 \ 1 \\
\end{bmatrix}u + \epsilon $$
  
  
  In the methods of moments, th variances can be calculated  
$$\sigma^2_g = \frac{MSE - \sigma^2_\epsilon}{n_{blocks}}$$
  
```{r}
mod <- lm(formula = yield ~ 1 + block + gen, data = data)
aov_table <- as.data.frame(anova(mod))
aov_table

mse_g <- aov_table["gen", "Mean Sq"]
var_e <- aov_table["Residuals", "Mean Sq"]
var_g <- (mse_g - var_e) / n_blks
var_g
```


Next, we need to build the design matrices and the variance covariances
$\mathbf{G}, \mathbf{R} \text{ and } \mathbf{V}$, where:
  
  $$G  = \sigma^2_g I = \sigma^2_g 
\begin{bmatrix}
1 \ 0 \ 0 \ 0\\
0 \ 1 \ 0 \ 0\\
0 \ 0 \ 1 \ 0\\
0 \ 0 \ 0 \ 1\\
\end{bmatrix}$$
  
  $$R  = \sigma^2_\epsilon I = \sigma^2_\epsilon 
\begin{bmatrix}
1 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \\
0 \ 1 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \\
0 \ 0 \ 1 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \\
0 \ 0 \ 0 \ 1 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \\
0 \ 0 \ 0 \ 0 \ 1 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \\
0 \ 0 \ 0 \ 0 \ 0 \ 1 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \\
0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 1 \ 0 \ 0 \ 0 \ 0 \ 0 \\
0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 1 \ 0 \ 0 \ 0 \ 0 \\
0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 1 \ 0 \ 0 \ 0 \\
0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 1 \ 0 \ 0 \\
0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 1 \ 0 \\
0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 0 \ 1 \\
\end{bmatrix}$$
  
  $$V  = Var(y) = Var(X\beta + Zu + \epsilon) = V(Zu) + V(\epsilon) = ZV(u)Z^T + R = ZGZ^T + R$$
  
  Thus, we can express the model as 

$$y \sim N(X\beta, ZGZ^T + R) \text{ or } y \sim MVN(\mu, V)$$
  
```{r}
X <- model.matrix(yield ~ 1 + block, data)
Z <- model.matrix(yield ~ -1 + gen, data)
y <- matrix(data[, "yield"]) |> na.omit()
print(X)
print(y)

G <- diag(x = var_g, nrow = n_gens)
R <- diag(x = var_e, nrow = n)
V <- Z %*% G %*% t(Z) + R
```


Now we have all we need to solve the Henderson equation

$$ 
  \underbrace{\begin{bmatrix}
    X^T R^{-1} X & X^T R^{-1} Z \\
    Z^T R^{-1} X & Z^T R^{-1} Z + G^{-1}
    \end{bmatrix}}_{\boldsymbol{C}} \begin{bmatrix}
\hat\beta\\ \hat u
\end{bmatrix} = \underbrace{\begin{bmatrix}
  X^T R^{-1} y \\
  Z^T R^{-1} y
  \end{bmatrix}}_{\boldsymbol{RHS}}
$$
  
  And therefore

$$ 
  \begin{bmatrix}
\hat\beta\\ \hat u
\end{bmatrix} = C^{-1} RHS, \text{ where } C = \begin{bmatrix}
C_{11} & C_{12} \\
C_{21} & C_{22}
\end{bmatrix} 
$$
  
  
```{r}
# Mixed Model Equations
C11 <- t(X) %*% chol2inv(chol(R)) %*% X
C12 <- t(X) %*% chol2inv(chol(R)) %*% Z
C21 <- t(Z) %*% chol2inv(chol(R)) %*% X
C22 <- t(Z) %*% chol2inv(chol(R)) %*% Z + solve(G)

# Coefficient matrix (LHS)
C <- as.matrix(
  rbind(
    cbind(C11, C12),
    cbind(C21, C22)
  )
)

# RHS
rhs <- rbind(
  t(X) %*% solve(R) %*% y,
  t(Z) %*% solve(R) %*% y
)

# Solution
C_inv <- chol2inv(chol(C))
rownames(C_inv) <- colnames(C_inv) <- rownames(C)
print(C_inv)
ans <- C_inv %*% rhs
ans
```

Besides that, BLUPs and BLUPs can be calculated separately as follows

$$ 
  \hat \beta = (X^TV^{-1}X)^{-1}X^TV^{-1}y
$$
  
  These are the generalized forms. Let's show how would $\hat \beta$ be calculated
assuming $V = \sigma^2_\epsilon I = \sigma^2_\epsilon$

$$
\beta = \sigma^2_\epsilon(X^TX)^{-1} \frac{X^Ty}{\sigma^2_\epsilon} = (X^TX)^{-1}X^Ty
$$

This looks familiar right? It's pure Ordinary Least Squares. 

Respectively, for BLUPs

$$ 
  \hat u = GZ^TV^{-1}(y-X\hat\beta)
$$
  
  
```{r}
V_inv <- solve(V)
betas <- solve(t(X) %*% V_inv %*% X) %*% t(X) %*% V_inv %*% y
u <- G %*% t(Z) %*% V_inv %*% (y - X %*% betas)
rownames(u) <- colnames(Z)
m <- rbind(betas, u)
rownames(m) <- c(rownames(betas), rownames(u))
m 
```

## 2) Fixed and Random Factors Implications

Next, we will explore these variance covariance matrices to underline the implications
of modeling effects either as random or as fixed. Specifically,  we will fit three different models:
  
  - The genotype as Random
- The genotype as Random and the Block as Fixed
- Both genotype and Block as Random

```{r}
mm_1 <- lmer(formula = yield ~ 1 + (1 | gen), data = data)
mm_2 <- lmer(formula = yield ~ 1 + block + (1 | gen), data = data)
mm_3 <- lmer(formula = yield ~ 1 + (1 | block) + (1 | gen), data = data)

ans <- map(list(mm_1, mm_2, mm_3), \(x) h_cullis(model = x, genotype = "gen", re_MME = TRUE))
col_pallete <- c("#440154", "#21908C", "#FDE725")
```

First, let's take a look at the $\mathbf{V}$ matrices

```{r}
#| fig-width: 14
#| fig-height: 5

Vs <- map(ans, \(x) as.matrix(x$Z %*% x$G %*% t(x$Z) + x$R))
titles <- c(
  "y ~ (1|gen)",
  "y ~ block + (1|gen)",
  "y ~ (1|block) + (1|gen)"
)
median <- median(unlist(Vs))
max <- max(unlist(Vs))

plot_function <- function(matrix, title, median, max){
  covcor_heat(matrix, corr = FALSE, size = 3) +
    scale_fill_gradient2(
      low = col_pallete[1],
      high = col_pallete[3],
      mid = col_pallete[2],
      midpoint = median,
      limit = c(0, max + 0.02),
      space = "Lab"
    ) +
    theme(legend.position = "top") +
    labs(title = title)
}

Vs_plots <- map2(Vs, titles, \(V, t) plot_function(V, t, median, max))
grid.arrange(grobs = Vs_plots, ncol = 3)
```

Notice that in the first model we only find correlation between observations that share the same genotype,
while no correlation is observed among different genotypes. When block information is added,
the correlation pattern remains only within genotypes, but we can clearly see how the variances decreases notably,
favouring the covariances.Finally, when both block and genotype are included as random effects,
we observe that observations within the same block also share information. Let's focus now on the
$C_{22}$ matrices

```{r}
C22 <- map(ans, \(x) as.matrix(x$C22.g))
median <- median(unlist(C22))
max <- max(unlist(C22))
C22_plots <- map2(C22, titles, \(C, t) plot_function(C, t, median, max))
grid.arrange(grobs = C22_plots, ncol = 3)
```


